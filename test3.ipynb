{"cells":[{"cell_type":"markdown","metadata":{},"source":["# RAG Demo\n","Using RAG to power up an LLM. We will use Langchain for our example. Langchain framework makes build LLM apps super easy.\n","\n","![./flow.png](./flow.png)"]},{"cell_type":"markdown","metadata":{},"source":["## Install Packages"]},{"cell_type":"code","execution_count":30,"metadata":{"vscode":{"languageId":"shellscript"}},"outputs":[{"name":"stdout","output_type":"stream","text":["850.70s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n","Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.0.342)\n","Requirement already satisfied: pypdf in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.17.1)\n","Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (2.0.23)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (3.9.1)\n","Requirement already satisfied: anyio<4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (3.7.1)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (0.6.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (1.33)\n","Requirement already satisfied: langchain-core<0.1,>=0.0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (0.0.7)\n","Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (0.0.67)\n","Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (1.26.2)\n","Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (2.5.2)\n","Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.6)\n","Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n","Requirement already satisfied: packaging>=17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","857.34s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n","Requirement already satisfied: pinecone-client in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.4)\n","Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (6.0.1)\n","Requirement already satisfied: loguru>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (0.7.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (4.8.0)\n","Requirement already satisfied: dnspython>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (2.4.2)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n","Requirement already satisfied: urllib3>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (2.1.0)\n","Requirement already satisfied: tqdm>=4.64.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (4.66.1)\n","Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client) (1.26.2)\n","Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n"]}],"source":["! pip install langchain pypdf\n","! pip install pinecone-client"]},{"cell_type":"markdown","metadata":{},"source":["## Steps\n","### Step 1: Extract\n","Load a document and extract the contents. For our example, I added a sample PDF from my article in docs folder."]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total docs:  19\n","First doc:  Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n","Last doc:  The model couldn’t come up with 6-word summary for the same sample.The sentence prematurely ended. S\n"]}],"source":["from langchain.document_loaders import PyPDFLoader\n","\n","# Load PDF\n","loaders = [\n","    PyPDFLoader(\"docs/GenAI-Part1.pdf\"),\n","    PyPDFLoader(\"docs/GenAI-Part2.pdf\")\n","]\n","docs = []\n","for loader in loaders:\n","    docs.extend(loader.load())\n","\n","# Look into the doc\n","print(\"Total docs: \", len(docs))\n","print(\"First doc: \", docs[0].page_content[0:100])\n","print(\"Last doc: \", docs[-1].page_content[0:100])"]},{"cell_type":"markdown","metadata":{},"source":["### Step 2: Split\n","Now split the document contents into smaller chunks."]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total documents on Charter Splitter:  4\n","Total documents on Recursive Charter Splitter:  6\n","Total documents on Token Splitter:  8\n"]}],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter\n","\n","# Character Splitter\n","c_splitter = CharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=150,\n","    separator = '\\n',\n","    length_function = len\n",")\n","\n","c_docs = c_splitter.split_documents(pages)\n","print(\"Total documents on Charter Splitter: \", len(c_docs))\n","\n","# Recursive Character Splitter\n","r_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=150, \n","    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",")\n","\n","r_docs = r_splitter.split_documents(pages)\n","print(\"Total documents on Recursive Charter Splitter: \", len(r_docs))\n","\n","# Token Splitter\n","t_splitter = TokenTextSplitter(\n","    chunk_size=150,\n","    chunk_overlap=10\n",")\n","\n","t_docs = t_splitter.split_documents(pages)\n","print(\"Total documents on Token Splitter: \", len(t_docs))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Step 3: Vector Store\n","Let's take our splits and embed them and then store them into a vector store. We will use [Pinecone](https://python.langchain.com/docs/integrations/vectorstores/pinecone) which is hosted."]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["from langchain.vectorstores import Pinecone\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","import pinecone\n","import os\n","\n","embedding = OpenAIEmbeddings()\n","\n","# initialize pinecone\n","pinecone.init(\n","    api_key=os.getenv(\"PINECONE_API_KEY\"),  # find at app.pinecone.io\n","    environment=os.getenv(\"PINECONE_ENV\"),  # next to api key in console\n",")\n","\n","index_name = \"demo1\"\n","# First, check if our index already exists. If it doesn't, we create it\n","if index_name not in pinecone.list_indexes():\n","    # we create a new index\n","    pinecone.create_index(name=index_name, metric=\"cosine\", dimension=1536)\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's store the pages of our PDF into Vector Store with Embeddings using OpenAI Embeddings."]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n","vectordb = Pinecone.from_documents(c_docs, embedding, index_name=index_name)\n","\n","# print(\"Total documents on Vector Store: \", len(vectordb.documents))"]},{"cell_type":"markdown","metadata":{},"source":["### Step 4: Retrieve\n","Let's retrieve with different methods"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Similarity Search\n","Page #0.0  : Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n","Page #0.0  : Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n","Page #0.0  : Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n","Page #0.0  : Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n","\n","MMR Search\n","Page #0.0  : Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n","Page #0.0  : Generative AI project — Part 1Muthu ArumugamThis article will help you understand how you can get in\n"]}],"source":["question = \"Who is the author?\"\n","\n","# Using Similarity Search\n","print(\"\\nSimilarity Search\")\n","docs = vectordb.similarity_search(question)\n","for d in docs:\n","    print(f\"Page #{d.metadata['page']}  : {d.page_content[:100]}\")\n","\n","# Using MMR to diversify the results\n","print(\"\\nMMR Search\")\n","docs = vectordb.max_marginal_relevance_search(question,k=2, fetch_k=3)\n","for d in docs:\n","    print(f\"Page #{d.metadata['page']}  : {d.page_content[:100]}\")"]},{"cell_type":"markdown","metadata":{},"source":["We need to do some compression to avoid unnecessary text around the content we are looking for."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n","  warnings.warn(\n","/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n","  warnings.warn(\n","/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n","  warnings.warn(\n","/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["from langchain.llms import OpenAI\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import LLMChainExtractor\n","\n","def pretty_print_docs(docs):\n","    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n","\n","# Wrap our vectorstore\n","llm = OpenAI(temperature=0)\n","compressor = LLMChainExtractor.from_llm(llm)\n","\n","compression_retriever = ContextualCompressionRetriever(\n","    base_compressor=compressor,\n","    base_retriever=vectordb.as_retriever(search_type=\"mmr\")\n",")\n","\n","compressed_docs = compression_retriever.get_relevant_documents(question)\n","pretty_print_docs(compressed_docs)"]},{"cell_type":"markdown","metadata":{},"source":["### Step 5: Generate\n","Time to call ChatGPT for a response based on our retrieval. We will use Question & Answer to call LLM.\n","\n","#### Using Retrieval QA Chain"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: Who is the author?\n","Answer: The author of the article is Muthu Arumugam.\n"]}],"source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import RetrievalQA\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectordb.as_retriever()\n",")\n","\n","result = qa_chain({\"query\": question})\n","print(f\"Question: {question}\\nAnswer: {result['result']}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Using Prompt"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: Who is the author?\n","Answer: The author is Muthu Arumugam. Thanks for asking!\n"]}],"source":["from langchain.prompts import PromptTemplate\n","\n","# Build prompt\n","template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n","{context}\n","Question: {question}\n","Helpful Answer:\"\"\"\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n","\n","# Run chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectordb.as_retriever(),\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")\n","\n","result = qa_chain({\"query\": question})\n","print(f\"Question: {question}\\nAnswer: {result['result']}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":2}
